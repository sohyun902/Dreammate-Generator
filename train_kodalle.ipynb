{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wll6SDmDjCz",
        "outputId": "f696cbcc-50f2-4cb9-c561-6e49d1b936f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FXU_-lJDl5O",
        "outputId": "63bd00af-5ccd-4c76-c633-41826dd23e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/dataset/preprocessed/all_images.zip, /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/dataset/preprocessed/all_images.zip.zip or /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/dataset/preprocessed/all_images.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "#! unzip -q '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/dataset/preprocessed/all_images.zip' -d '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/preprocessed'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XIDn5_wDE2Ek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0abb6d7-ddae-4d2f-a83c-5063c2b555a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of files in '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/preprocessed/all_images': 54486\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def count_files_in_directory(directory):\n",
        "    # ÌååÏùº Í∞úÏàòÎ•º ÏÑ∏Í∏∞ ÏúÑÌïú Ï¥àÍ∏∞Í∞í ÏÑ§Ï†ï\n",
        "    file_count = 0\n",
        "\n",
        "    # ÎîîÎ†âÌÜ†Î¶¨ ÏïàÏùò ÌååÏùº Î∞è Ìè¥Îçî Î™©Î°ù Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        # ÌååÏùº Î™©Î°ùÏùò Í∏∏Ïù¥Î•º ÌååÏùº Í∞úÏàòÏóê ÎçîÌï®\n",
        "        file_count += len(files)\n",
        "\n",
        "    return file_count\n",
        "\n",
        "# ÏÇ¨Ïö©Ìï† Ìè¥Îçî Í≤ΩÎ°úÎ•º ÏßÄÏ†ï\n",
        "directory_path = '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/preprocessed/all_images'\n",
        "\n",
        "# Ìï®Ïàò Ìò∏Ï∂ú Î∞è Í≤∞Í≥º Ï∂úÎ†•\n",
        "print(f\"Total number of files in '{directory_path}': {count_files_in_directory(directory_path)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KODALLE"
      ],
      "metadata": {
        "id": "y6-5iNjeWffB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install wandb\n",
        "! wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7MQhxxCVcQv",
        "outputId": "dfb5f5f8-481b-4919-d154-6d16b5a023d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.17.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.5.1-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.5.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install adamp\n",
        "! pip install loader\n",
        "! pip install dalle_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kpd_8FEmWj3L",
        "outputId": "287a3dfc-94cc-4c25-893c-11acd2b99843"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adamp\n",
            "  Downloading adamp-0.3.0.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: adamp\n",
            "  Building wheel for adamp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adamp: filename=adamp-0.3.0-py3-none-any.whl size=5980 sha256=badce1f94dd5481b5e1a578cac806efa8081a3f2c7b107fd847fb029ea92a69e\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/ad/0f/b41b1c45b18c66e5eef5d2254415af8055c7e2b0934145157d\n",
            "Successfully built adamp\n",
            "Installing collected packages: adamp\n",
            "Successfully installed adamp-0.3.0\n",
            "Collecting loader\n",
            "  Downloading loader-2017.9.11-py3-none-any.whl (5.9 kB)\n",
            "Collecting bs4 (from loader)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->loader) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->loader) (2.5)\n",
            "Installing collected packages: bs4, loader\n",
            "Successfully installed bs4-0.0.2 loader-2017.9.11\n",
            "Collecting dalle_pytorch\n",
            "  Downloading dalle_pytorch-1.6.6-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting axial-positional-embedding (from dalle_pytorch)\n",
            "  Downloading axial_positional_embedding-0.2.1.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting DALL-E (from dalle_pytorch)\n",
            "  Downloading DALL_E-0.1-py3-none-any.whl (6.0 kB)\n",
            "Collecting einops>=0.3.2 (from dalle_pytorch)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy (from dalle_pytorch)\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dalle_pytorch) (24.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from dalle_pytorch) (9.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from dalle_pytorch) (2024.5.15)\n",
            "Collecting rotary-embedding-torch (from dalle_pytorch)\n",
            "  Downloading rotary_embedding_torch-0.6.2-py3-none-any.whl (5.3 kB)\n",
            "Collecting taming-transformers-rom1504 (from dalle_pytorch)\n",
            "  Downloading taming_transformers_rom1504-0.0.6-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from dalle_pytorch) (0.19.1)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from dalle_pytorch) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from dalle_pytorch) (0.18.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from dalle_pytorch) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dalle_pytorch) (4.66.4)\n",
            "Collecting youtokentome (from dalle_pytorch)\n",
            "  Downloading youtokentome-1.0.6.tar.gz (86 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting WebDataset (from dalle_pytorch)\n",
            "  Downloading webdataset-0.2.86-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->dalle_pytorch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->dalle_pytorch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->dalle_pytorch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->dalle_pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->dalle_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->dalle_pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6->dalle_pytorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6->dalle_pytorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6->dalle_pytorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6->dalle_pytorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6->dalle_pytorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6->dalle_pytorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6->dalle_pytorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6->dalle_pytorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6->dalle_pytorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.6->dalle_pytorch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6->dalle_pytorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->dalle_pytorch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->dalle_pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blobfile (from DALL-E->dalle_pytorch)\n",
            "  Downloading blobfile-2.1.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy (from DALL-E->dalle_pytorch)\n",
            "  Downloading mypy-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from DALL-E->dalle_pytorch) (1.25.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from DALL-E->dalle_pytorch) (7.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from DALL-E->dalle_pytorch) (2.31.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->dalle_pytorch) (0.2.13)\n",
            "Collecting beartype (from rotary-embedding-torch->dalle_pytorch)\n",
            "  Downloading beartype-0.18.5-py3-none-any.whl (917 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m917.8/917.8 kB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf>=2.0.0 (from taming-transformers-rom1504->dalle_pytorch)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning>=1.0.8 (from taming-transformers-rom1504->dalle_pytorch)\n",
            "  Downloading pytorch_lightning-2.2.5-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m802.3/802.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->dalle_pytorch) (0.23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->dalle_pytorch) (6.0.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->dalle_pytorch) (0.4.3)\n",
            "Collecting braceexpand (from WebDataset->dalle_pytorch)\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.10/dist-packages (from youtokentome->dalle_pytorch) (8.1.7)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0.0->taming-transformers-rom1504->dalle_pytorch)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle_pytorch)\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities>=0.8.0 (from pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle_pytorch)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Collecting pycryptodomex~=3.8 (from blobfile->DALL-E->dalle_pytorch)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile->DALL-E->dalle_pytorch) (2.0.7)\n",
            "Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile->DALL-E->dalle_pytorch) (4.9.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->dalle_pytorch) (2.1.5)\n",
            "Collecting mypy-extensions>=1.0.0 (from mypy->DALL-E->dalle_pytorch)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy->DALL-E->dalle_pytorch) (2.0.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->DALL-E->dalle_pytorch) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->DALL-E->dalle_pytorch) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->DALL-E->dalle_pytorch) (1.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->DALL-E->dalle_pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->DALL-E->dalle_pytorch) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->DALL-E->dalle_pytorch) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->dalle_pytorch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->torch>=1.6->dalle_pytorch) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=1.0.8->taming-transformers-rom1504->dalle_pytorch) (67.7.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=1.6->dalle_pytorch) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=1.6->dalle_pytorch) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=1.6->dalle_pytorch) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=1.6->dalle_pytorch) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=1.6->dalle_pytorch) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=1.6->dalle_pytorch) (4.0.3)\n",
            "Building wheels for collected packages: axial-positional-embedding, youtokentome, antlr4-python3-runtime\n",
            "  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-py3-none-any.whl size=2882 sha256=71c4aaf55d3c14763aaab03c8e7873e8000e2df679cb81820ef21954dc77da0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/cb/39/7ce7ff2d2fd37cfe1fe7b3a3c43cf410632b2ad3b3f3986d73\n",
            "  Building wheel for youtokentome (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for youtokentome: filename=youtokentome-1.0.6-cp310-cp310-linux_x86_64.whl size=1951498 sha256=feaee0fc2c6b847652e7ab502e53cc8371fdd9cb6c817ff94f22b1130104495f\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/85/f8/301d2ba45f43f30bed2fe413efa760bc726b8b660ed9c2900c\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=20a0cff31cc6377b1867d524a3c109beccbe2357e46c19d81fa74ca784da057a\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built axial-positional-embedding youtokentome antlr4-python3-runtime\n",
            "Installing collected packages: braceexpand, antlr4-python3-runtime, youtokentome, WebDataset, pycryptodomex, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, lightning-utilities, ftfy, einops, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, mypy, blobfile, nvidia-cusolver-cu12, torchmetrics, rotary-embedding-torch, axial-positional-embedding, pytorch-lightning, DALL-E, taming-transformers-rom1504, dalle_pytorch\n",
            "Successfully installed DALL-E-0.1 WebDataset-0.2.86 antlr4-python3-runtime-4.9.3 axial-positional-embedding-0.2.1 beartype-0.18.5 blobfile-2.1.1 braceexpand-0.1.7 dalle_pytorch-1.6.6 einops-0.8.0 ftfy-6.2.0 lightning-utilities-0.11.2 mypy-1.10.0 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 pycryptodomex-3.20.0 pytorch-lightning-2.2.5 rotary-embedding-torch-0.6.2 taming-transformers-rom1504-0.0.6 torchmetrics-1.4.0.post0 youtokentome-1.0.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "293c4926aff74b1983a63764ba49bf29"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "X0Jb6T7DWpsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/train.py' --wandb_name \"Kodalle\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLRUG3HLWpdc",
        "outputId": "a111c34d-3108-4e48-bad9-d3dfad841ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n",
            "Restored from /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/epoch=000007.ckpt\n",
            "Loaded VQGAN from /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/epoch=000007.ckpt and /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/loaded_VQGAN_blue.yaml\n",
            "full\n",
            "1024 16 16\n",
            "full\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mannie2675\u001b[0m (\u001b[33mannie26751\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240611_184408-crqzd8pq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mKodalle\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle/runs/crqzd8pq\u001b[0m\n",
            "0 0 loss - 9.941685676574707\n",
            "2024-06-11 18:45:42.118599: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-11 18:45:42.118656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-11 18:45:42.233651: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-11 18:45:44.664267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "1 0 loss - 3.8074951171875\n",
            "2 0 loss - 3.098296642303467\n",
            "3 0 loss - 2.663395643234253\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: epoch ‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  iter ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  loss ‚ñà‚ñÇ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: epoch 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  iter 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  loss 2.6634\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mKodalle\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle/runs/crqzd8pq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240611_184408-crqzd8pq/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# epoch = 4, barch_size = 24\n",
        "! python '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/train.py' --wandb_name \"Kodalle\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPKy_iuClUNq",
        "outputId": "d4e094c0-ee04-4e69-8527-c6ea836966a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n",
            "Restored from /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/epoch=000007.ckpt\n",
            "Loaded VQGAN from /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/epoch=000007.ckpt and /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/loaded_VQGAN_blue.yaml\n",
            "full\n",
            "<loader.TextImageDataset object at 0x7d179399bf40>\n",
            "1024 16 16\n",
            "full\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mannie2675\u001b[0m (\u001b[33mannie26751\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240612_143705-d9fjf21k\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mKodalle\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle/runs/d9fjf21k\u001b[0m\n",
            "0 0 loss - 9.952756881713867\n",
            "2024-06-12 14:37:49.898935: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-12 14:37:49.899014: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-12 14:37:50.015638: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-12 14:37:56.683341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "0 20 loss - 4.726798057556152\n",
            "0 40 loss - 4.378009796142578\n",
            "0 60 loss - 3.948068618774414\n",
            "1 0 loss - 3.915064573287964\n",
            "1 20 loss - 3.707751512527466\n",
            "1 40 loss - 3.477161407470703\n",
            "1 60 loss - 3.2220005989074707\n",
            "2 0 loss - 3.1179800033569336\n",
            "2 20 loss - 3.1702585220336914\n",
            "2 40 loss - 3.0158183574676514\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/train.py\", line 212, in <module>\n",
            "    train()\n",
            "  File \"/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/train.py\", line 38, in train\n",
            "    loss = dalle(text, images, mask=mask, return_loss=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/dalle/models.py\", line 249, in forward\n",
            "    out = self.transformer(tokens)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dalle_pytorch/transformer.py\", line 332, in forward\n",
            "    return self.layers(x, rotary_pos_emb = self.pos_emb, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dalle_pytorch/reversible.py\", line 156, in forward\n",
            "    out =  _ReversibleFunction.apply(x, blocks, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\", line 553, in apply\n",
            "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dalle_pytorch/reversible.py\", line 113, in forward\n",
            "    x = block(x, **kwarg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dalle_pytorch/reversible.py\", line 65, in forward\n",
            "    y1 = x1 + self.f(x2, record_rng=self.training, **f_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dalle_pytorch/reversible.py\", line 40, in forward\n",
            "    return self.net(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dalle_pytorch/transformer.py\", line 88, in forward\n",
            "    return self.fn(x, **kwargs) * self.scale\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dalle_pytorch/transformer.py\", line 101, in forward\n",
            "    x = self.fn(x, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dalle_pytorch/transformer.py\", line 71, in forward\n",
            "    return self.fn(x, cache=cache, cache_key=self.cache_key, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dalle_pytorch/transformer.py\", line 200, in forward\n",
            "    return self.fn(x, cache=cache, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dalle_pytorch/transformer.py\", line 71, in forward\n",
            "    return self.fn(x, cache=cache, cache_key=self.cache_key, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dalle_pytorch/attention.py\", line 67, in forward\n",
            "    q, k, v = apply_pos_emb(rotary_pos_emb[..., offset:, :], (q, k, v))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dalle_pytorch/attention.py\", line 35, in apply_pos_emb\n",
            "    return tuple(map(lambda t: apply_rotary_emb(pos_emb, t), qkv))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dalle_pytorch/attention.py\", line 35, in <lambda>\n",
            "    return tuple(map(lambda t: apply_rotary_emb(pos_emb, t), qkv))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\", line 16, in decorate_autocast\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/rotary_embedding_torch/rotary_embedding_torch.py\", line 49, in apply_rotary_emb\n",
            "    t = (t * freqs.cos() * scale) + (rotate_half(t) * freqs.sin() * scale)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# epoch = 30, barch_size = 16\n",
        "! python '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/train.py' --wandb_name \"Kodalle_30\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2cba502-0a70-4a88-d0a0-0cc9132835ef",
        "id": "5a6fbLMuB2BW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n",
            "Restored from /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/epoch=000007.ckpt\n",
            "Loaded VQGAN from /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/epoch=000007.ckpt and /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/loaded_VQGAN_blue.yaml\n",
            "full\n",
            "<loader.TextImageDataset object at 0x7c951cc8bfd0>\n",
            "1024 16 16\n",
            "full\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mannie2675\u001b[0m (\u001b[33mannie26751\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240612_093435-8uf8mno7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mKodalle_30\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle/runs/8uf8mno7\u001b[0m\n",
            "0 0 loss - 9.93525505065918\n",
            "2024-06-12 09:34:55.967978: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-12 09:34:55.968056: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-12 09:34:56.116646: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-12 09:34:56.389721: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-12 09:35:06.150747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "1 0 loss - 3.866851329803467\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/train.py\", line 212, in <module>\n",
            "    train()\n",
            "  File \"/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/train.py\", line 43, in train\n",
            "    opt.step()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 391, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/adamp/adamp.py\", line 91, in step\n",
            "    perturb, wd_ratio = self._projection(p, grad, perturb, group['delta'], group['wd_ratio'], group['eps'])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/adamp/adamp.py\", line 37, in _projection\n",
            "    cosine_sim = self._cosine_similarity(grad, p.data, eps, view_func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/adamp/adamp.py\", line 30, in _cosine_similarity\n",
            "    return F.cosine_similarity(x, y, dim=1, eps=eps).abs_()\n",
            "KeyboardInterrupt\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: epoch ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  iter ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  loss ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: epoch 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  iter 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  loss 3.86685\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mKodalle_30\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle/runs/8uf8mno7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 2 media file(s), 1 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240612_093435-8uf8mno7/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# epoch = 20, barch_size = 16\n",
        "! python '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/train.py' --wandb_name \"Kodalle_20\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae6728b-b754-468a-a2da-bd5cb81cf7f7",
        "id": "zLhLqQAQr701"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer_config.json: 100% 375/375 [00:00<00:00, 1.63MB/s]\n",
            "vocab.txt: 100% 248k/248k [00:00<00:00, 1.50MB/s]\n",
            "tokenizer.json: 100% 752k/752k [00:00<00:00, 3.33MB/s]\n",
            "special_tokens_map.json: 100% 173/173 [00:00<00:00, 735kB/s]\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100% 528M/528M [00:03<00:00, 160MB/s]\n",
            "Downloading vgg_lpips model from https://heibox.uni-heidelberg.de/f/607503859c864bc1b30b/?dl=1 to taming/modules/autoencoder/lpips/vgg.pth\n",
            "8.19kB [00:00, 395kB/s]        \n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n",
            "Restored from /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/epoch=000007.ckpt\n",
            "Loaded VQGAN from /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/epoch=000007.ckpt and /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/loaded_VQGAN_blue.yaml\n",
            "full\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/train.py\", line 173, in <module>\n",
            "    dataset_visual = ImgDatasetExample(\n",
            "  File \"/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/loader.py\", line 133, in __init__\n",
            "    self.image_files = [\n",
            "  File \"/usr/lib/python3.10/pathlib.py\", line 1034, in glob\n",
            "    for p in selector.select_from(self):\n",
            "  File \"/usr/lib/python3.10/pathlib.py\", line 493, in _select_from\n",
            "    for p in successor_select(starting_point, is_dir, exists, scandir):\n",
            "  File \"/usr/lib/python3.10/pathlib.py\", line 440, in _select_from\n",
            "    with scandir(parent_path) as scandir_it:\n",
            "OSError: [Errno 5] Input/output error: '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/preprocessed/all_images'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# epoch = 5, batch_size = 16\n",
        "! python '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/train.py' --wandb_name \"Kodalle_5\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ni1vFgbG5bo",
        "outputId": "cfeab21a-d0b7-44c4-dc3f-b66bbe6a0aa5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n",
            "Restored from /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/epoch=000007.ckpt\n",
            "Loaded VQGAN from /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/epoch=000007.ckpt and /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/loaded_VQGAN_blue.yaml\n",
            "full\n",
            "<loader.TextImageDataset object at 0x7835a6252bf0>\n",
            "1024 16 16\n",
            "full\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mannie2675\u001b[0m (\u001b[33mannie26751\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240612_161743-7ics3frh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mKodalle_5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle/runs/7ics3frh\u001b[0m\n",
            "0 0 loss - 9.947244644165039\n",
            "2024-06-12 16:17:58.977231: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-12 16:17:58.977301: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-12 16:17:59.097346: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-12 16:17:59.325929: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-12 16:18:10.390575: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "0 20 loss - 4.6909379959106445\n",
            "0 40 loss - 4.322117328643799\n",
            "0 60 loss - 3.993182420730591\n",
            "1 0 loss - 3.883690595626831\n",
            "1 20 loss - 3.6750950813293457\n",
            "1 40 loss - 3.500836133956909\n",
            "1 60 loss - 3.239720106124878\n",
            "2 0 loss - 3.0891551971435547\n",
            "2 20 loss - 2.9327285289764404\n",
            "2 40 loss - 2.92680287361145\n",
            "2 60 loss - 2.8224544525146484\n",
            "3 0 loss - 2.578993797302246\n",
            "3 20 loss - 2.499619722366333\n",
            "3 40 loss - 2.6003823280334473\n",
            "3 60 loss - 2.5117835998535156\n",
            "4 0 loss - 2.258887529373169\n",
            "4 20 loss - 2.1794657707214355\n",
            "4 40 loss - 2.3197033405303955\n",
            "4 60 loss - 2.2995362281799316\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  iter ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÅ‚ñÉ‚ñÜ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  loss ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: epoch 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  iter 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  loss 2.29954\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mKodalle_5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle/runs/7ics3frh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/annie26751/Kodalle\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 10 media file(s), 5 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240612_161743-7ics3frh/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test"
      ],
      "metadata": {
        "id": "4w_lsuV0cqEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqHzrnatea60",
        "outputId": "8e0e47b3-a5ff-4f92-d812-47a4e44679e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting utils\n",
            "  Downloading utils-1.0.2.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: utils\n",
            "  Building wheel for utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13906 sha256=135959a0c188fe15d0de7c6d168c4caf469f244d0f562e03553aa8a37a0c55cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/39/f5/9d0ca31dba85773ececf0a7f5469f18810e1c8a8ed9da28ca7\n",
            "Successfully built utils\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from einops import repeat\n",
        "from axial_positional_embedding import AxialPositionalEmbedding\n",
        "from einops import rearrange\n",
        "\n",
        "from dalle_pytorch import DiscreteVAE\n",
        "from dalle_pytorch.vae import OpenAIDiscreteVAE, VQGanVAE\n",
        "\n",
        "from dalle_pytorch.transformer import Transformer, DivideMax\n",
        "from utils import *\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DALLE_Klue_Roberta(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        # dim,\n",
        "        vae,\n",
        "        num_text_tokens=10000,\n",
        "        text_seq_len=256,\n",
        "        depth,\n",
        "        heads=8,\n",
        "        dim_head=64,\n",
        "        reversible=False,\n",
        "        attn_dropout=0.0,\n",
        "        ff_dropout=0,\n",
        "        sparse_attn=False,\n",
        "        attn_types=None,\n",
        "        loss_img_weight=7,\n",
        "        stable=False,\n",
        "        sandwich_norm=False,\n",
        "        shift_tokens=True,\n",
        "        rotary_emb=False,\n",
        "        wte_dir=None,\n",
        "        wpe_dir=None,\n",
        "    ):\n",
        "\n",
        "        super().__init__()\n",
        "        assert isinstance(\n",
        "            vae, (DiscreteVAE, OpenAIDiscreteVAE, VQGanVAE)\n",
        "        ), \"vae must be an instance of DiscreteVAE\"\n",
        "        image_size = vae.image_size\n",
        "        num_image_tokens = vae.num_tokens\n",
        "        image_fmap_size = vae.image_size // (2 ** vae.num_layers)\n",
        "        image_seq_len = image_fmap_size ** 2\n",
        "\n",
        "        num_text_tokens = (\n",
        "            num_text_tokens + text_seq_len\n",
        "        )  # reserve unique padding tokens for each position (text seq len)\n",
        "\n",
        "        def always(value):\n",
        "          return lambda *args, **kwargs: value\n",
        "\n",
        "        self.text_emb = torch.load(wte_dir)\n",
        "        dim = self.text_emb.weight.shape[1]\n",
        "        self.image_emb = nn.Embedding(num_image_tokens, dim)\n",
        "        print(dim, image_fmap_size, image_fmap_size)\n",
        "        self.text_pos_emb = (\n",
        "            torch.load(wpe_dir) if not rotary_emb else always(0)\n",
        "        )  # +1 for <bos>\n",
        "        self.image_pos_emb = (\n",
        "            AxialPositionalEmbedding(\n",
        "                dim, axial_shape=(image_fmap_size, image_fmap_size)\n",
        "            )\n",
        "            if not rotary_emb\n",
        "            else always(0)\n",
        "        )\n",
        "\n",
        "        self.num_text_tokens = num_text_tokens  # for offsetting logits index and calculating cross entropy loss\n",
        "        self.num_image_tokens = num_image_tokens\n",
        "\n",
        "        self.text_seq_len = text_seq_len\n",
        "        self.image_seq_len = image_seq_len\n",
        "\n",
        "        seq_len = text_seq_len + image_seq_len\n",
        "        total_tokens = num_text_tokens + num_image_tokens\n",
        "        self.total_tokens = total_tokens\n",
        "        self.total_seq_len = seq_len\n",
        "\n",
        "        self.vae = vae\n",
        "\n",
        "        def set_requires_grad(model, value):\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = value\n",
        "        set_requires_grad(self.vae, False)  # freeze VAE from being trained\n",
        "\n",
        "        self.transformer = Transformer(\n",
        "            dim=dim,\n",
        "            causal=True,\n",
        "            seq_len=seq_len,\n",
        "            depth=depth,\n",
        "            heads=heads,\n",
        "            dim_head=dim_head,\n",
        "            reversible=reversible,\n",
        "            attn_dropout=attn_dropout,\n",
        "            ff_dropout=ff_dropout,\n",
        "            attn_types=attn_types,\n",
        "            image_fmap_size=image_fmap_size,\n",
        "            sparse_attn=sparse_attn,\n",
        "            stable=stable,\n",
        "            sandwich_norm=sandwich_norm,\n",
        "            shift_tokens=shift_tokens,\n",
        "            rotary_emb=rotary_emb,\n",
        "        )\n",
        "\n",
        "        self.stable = stable\n",
        "\n",
        "        if stable:\n",
        "            self.norm_by_max = DivideMax(dim=-1)\n",
        "\n",
        "        self.to_logits = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, self.total_tokens),\n",
        "        )\n",
        "\n",
        "        seq_range = torch.arange(seq_len)\n",
        "        logits_range = torch.arange(total_tokens)\n",
        "\n",
        "        seq_range = rearrange(seq_range, \"n -> () n ()\")\n",
        "        logits_range = rearrange(logits_range, \"d -> () () d\")\n",
        "\n",
        "        logits_mask = (\n",
        "            (seq_range >= text_seq_len) & (logits_range < num_text_tokens)\n",
        "        ) | ((seq_range < text_seq_len) & (logits_range >= num_text_tokens))\n",
        "\n",
        "        self.register_buffer(\"logits_mask\", logits_mask, persistent=False)\n",
        "        self.loss_img_weight = loss_img_weight\n",
        "\n",
        "    @torch.no_grad()\n",
        "\n",
        "    def exists(obj):\n",
        "            return obj is not None\n",
        "\n",
        "    #eval_decorator\n",
        "    def generate_images(\n",
        "        self,\n",
        "        encoded_text,\n",
        "        *,\n",
        "        clip=None,\n",
        "        filter_thres=0.5,\n",
        "        temperature=1.0,\n",
        "        img=None,\n",
        "        num_init_img_tokens=None,\n",
        "        img_num=1,\n",
        "    ):\n",
        "        text = encoded_text['input_ids']\n",
        "        text=repeat(text,'() n -> b n',b=img_num)\n",
        "        mask=encoded_text['attention_mask']\n",
        "        vae, text_seq_len, image_seq_len, num_text_tokens = (\n",
        "            self.vae,\n",
        "            self.text_seq_len,\n",
        "            self.image_seq_len,\n",
        "            self.num_text_tokens,\n",
        "        )\n",
        "        total_len = text_seq_len + image_seq_len\n",
        "\n",
        "        text = text[:, :text_seq_len]  # make sure text is within bounds\n",
        "        out = text\n",
        "\n",
        "\n",
        "        if exists(img):\n",
        "            image_size = vae.image_size\n",
        "            assert (\n",
        "                img.shape[1] == 3\n",
        "                and img.shape[2] == image_size\n",
        "                and img.shape[3] == image_size\n",
        "                ), f\"input image must have the correct image size {image_size}\"\n",
        "\n",
        "            indices = vae.get_codebook_indices(img)\n",
        "            num_img_tokens = default(\n",
        "                num_init_img_tokens, int(0.4375 * image_seq_len)\n",
        "            )  # OpenAI used 14 * 32 initial tokens to prime\n",
        "            assert (\n",
        "                num_img_tokens < image_seq_len\n",
        "            ), \"number of initial image tokens for priming must be less than the total image token sequence length\"\n",
        "\n",
        "            indices = indices[:, :num_img_tokens]\n",
        "            print(\"out shape:\", out.shape)\n",
        "            print(\"sample shape:\", sample.shape)\n",
        "            out = torch.cat((out, indices), dim=-1)\n",
        "\n",
        "        for cur_len in tqdm(range(out.shape[1], total_len)):\n",
        "          is_image = cur_len >= text_seq_len\n",
        "\n",
        "          text, image = out[:, :text_seq_len], out[:, text_seq_len:]\n",
        "\n",
        "          logits = self(text, image, mask=mask)[:, -1, :]\n",
        "\n",
        "          filtered_logits = top_k(logits, thres=filter_thres)\n",
        "          probs = F.softmax(filtered_logits / temperature, dim=-1)\n",
        "          sample = torch.multinomial(probs, 1)\n",
        "\n",
        "          # Ïó¨Í∏∞ÏóêÏÑú Ï∞®ÏõêÏùÑ Ï°∞Ï†ïÌï©ÎãàÎã§.\n",
        "          if sample.dim() == 1:\n",
        "              sample = sample.unsqueeze(1)\n",
        "\n",
        "          # Ï∞®ÏõêÏù¥ Ï°∞Ï†ïÎêú ÌÖêÏÑúÎ•º Ïó∞Í≤∞Ìï©ÎãàÎã§.\n",
        "          sample -= (num_text_tokens if is_image else 0)  # ÌïÑÏöîÌïú Ï°∞Ï†ï\n",
        "          out = torch.cat((out, sample), dim=-1)\n",
        "\n",
        "          if out.shape[1] <= text_seqlen:\n",
        "              mask = F.pad(mask, (0, 1), value=True)\n",
        "\n",
        "\n",
        "          img_seq = out[:, -image_seq_len:]\n",
        "          images = vae.decode(img_seq)\n",
        "\n",
        "        if exists(clip):\n",
        "            #encoded_text = encoded_text.to(\"cuda\")\n",
        "            text_embeds, image_embeds = clip(encoded_text, images)\n",
        "            logits = text_embeds @ image_embeds.T\n",
        "            return images, logits\n",
        "\n",
        "        return images\n",
        "    def forward(self, text, image=None, mask=None, return_loss=False):\n",
        "        assert (\n",
        "            text.shape[-1] == self.text_seq_len\n",
        "        ), f\"the length {text.shape[-1]} of the text tokens you passed in does not have the correct length ({self.text_seq_len})\"\n",
        "        device, total_seq_len = text.device, self.total_seq_len\n",
        "\n",
        "        # make sure padding in text tokens get unique padding token id\n",
        "        text = F.pad(text, (1, 0), value=0)\n",
        "\n",
        "        tokens = self.text_emb(text)\n",
        "        tokens += self.text_pos_emb(torch.arange(text.shape[1], device=device))\n",
        "\n",
        "        seq_len = tokens.shape[1]\n",
        "\n",
        "        if exists(image) and not is_empty(image):\n",
        "            is_raw_image = len(image.shape) == 4\n",
        "\n",
        "            if is_raw_image:\n",
        "                image_size = self.vae.image_size\n",
        "                assert tuple(image.shape[1:]) == (\n",
        "                    3,\n",
        "                    image_size,\n",
        "                    image_size,\n",
        "                ), f\"invalid image of dimensions {image.shape} passed in during training\"\n",
        "\n",
        "                image = self.vae.get_codebook_indices(image)\n",
        "            image_len = image.shape[1]\n",
        "            image_emb = self.image_emb(image)\n",
        "            image_emb += self.image_pos_emb(image_emb)\n",
        "\n",
        "            tokens = torch.cat((tokens, image_emb), dim=1)\n",
        "\n",
        "            seq_len += image_len\n",
        "\n",
        "        # when training, if the length exceeds the total text + image length\n",
        "        # remove the last token, since it needs not to be trained\n",
        "\n",
        "        if tokens.shape[1] > total_seq_len:\n",
        "            seq_len -= 1\n",
        "            tokens = tokens[:, :-1]\n",
        "\n",
        "        if self.stable:\n",
        "            alpha = 0.1\n",
        "            tokens = tokens * alpha + tokens.detach() * (1 - alpha)\n",
        "\n",
        "        out = self.transformer(tokens)\n",
        "\n",
        "        if self.stable:\n",
        "            out = self.norm_by_max(out)\n",
        "\n",
        "        logits = self.to_logits(out)\n",
        "\n",
        "        # mask logits to make sure text predicts text (except last token), and image predicts image\n",
        "\n",
        "        logits_mask = self.logits_mask[:, :seq_len]\n",
        "        max_neg_value = -torch.finfo(logits.dtype).max\n",
        "        logits.masked_fill_(logits_mask, max_neg_value)\n",
        "\n",
        "        if not return_loss:\n",
        "            return logits\n",
        "\n",
        "        assert exists(image), \"when training, image must be supplied\"\n",
        "\n",
        "        offsetted_image = image + self.num_text_tokens\n",
        "        labels = torch.cat((text[:, 1:], offsetted_image), dim=1)\n",
        "\n",
        "        logits = rearrange(logits, \"b n c -> b c n\")\n",
        "\n",
        "        loss_text = F.cross_entropy(\n",
        "            logits[:, :, : self.text_seq_len], labels[:, : self.text_seq_len]\n",
        "        )\n",
        "        loss_img = F.cross_entropy(\n",
        "            logits[:, :, self.text_seq_len :], labels[:, self.text_seq_len :]\n",
        "        )\n",
        "\n",
        "        loss = (loss_text + self.loss_img_weight * loss_img) / (\n",
        "            self.loss_img_weight + 1\n",
        "        )\n",
        "        return loss"
      ],
      "metadata": {
        "id": "XtxFnIKjdEtE"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from dalle_pytorch import VQGanVAE\n",
        "#from dalle.models import DALLE_Klue_Roberta\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "import yaml\n",
        "from easydict import EasyDict\n",
        "\n",
        "\n",
        "\n",
        "dalle_config_path = '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/configs/dalle_config.yaml'\n",
        "dalle_path = '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/dalle_uk.pt'\n",
        "\n",
        "vqgan_config_path = '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/loaded_VQGAN_blue.yaml'\n",
        "vqgan_path = '/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/epoch=000007.ckpt'\n",
        "\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFEj9kbqcrEA",
        "outputId": "f2ec717f-d1c9-479c-bf02-e5af13e32cfb"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n",
        "\n",
        "with open(dalle_config_path, \"r\") as f:\n",
        "    dalle_config = yaml.load(f, Loader=yaml.Loader)\n",
        "    DALLE_CFG = EasyDict(dalle_config[\"DALLE_CFG\"])\n",
        "\n",
        "DALLE_CFG.VOCAB_SIZE = tokenizer.vocab_size\n",
        "\n",
        "vae = VQGanVAE(\n",
        "    vqgan_model_path=vqgan_path,\n",
        "    vqgan_config_path=vqgan_config_path\n",
        ")\n",
        "\n",
        "DALLE_CFG.IMAGE_SIZE = vae.image_size\n",
        "\n",
        "dalle_params = dict(\n",
        "    num_text_tokens=tokenizer.vocab_size,\n",
        "    text_seq_len=DALLE_CFG.TEXT_SEQ_LEN,\n",
        "    depth=DALLE_CFG.DEPTH,\n",
        "    heads=DALLE_CFG.HEADS,\n",
        "    dim_head=DALLE_CFG.DIM_HEAD,\n",
        "    reversible=DALLE_CFG.REVERSIBLE,\n",
        "    loss_img_weight=DALLE_CFG.LOSS_IMG_WEIGHT,\n",
        "    attn_types=DALLE_CFG.ATTN_TYPES,\n",
        "    ff_dropout=DALLE_CFG.FF_DROPOUT,\n",
        "    attn_dropout=DALLE_CFG.ATTN_DROPOUT,\n",
        "    stable=DALLE_CFG.STABLE,\n",
        "    shift_tokens=DALLE_CFG.SHIFT_TOKENS,\n",
        "    rotary_emb=DALLE_CFG.ROTARY_EMB,\n",
        ")\n",
        "\n",
        "dalle = DALLE_Klue_Roberta(\n",
        "    vae=vae,\n",
        "    wte_dir=\"/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/models/roberta_large_wte.pt\",\n",
        "    wpe_dir=\"/content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/models/roberta_large_wpe.pt\",\n",
        "    **dalle_params\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "loaded_obj = torch.load(dalle_path, map_location=torch.device('cuda:0'))\n",
        "dalle_params, vae_params, weights = loaded_obj['hparams'], loaded_obj['vae_params'], loaded_obj['weights']\n",
        "dalle.load_state_dict(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOk1Pk_sdBVr",
        "outputId": "af0d16c4-6019-4329-9d8b-b760b33a31f8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n",
            "Restored from /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/epoch=000007.ckpt\n",
            "Loaded VQGAN from /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/epoch=000007.ckpt and /content/drive/MyDrive/ai ·Ñâ·Öµ·Ñâ·Ö≥·Ñê·Ö¶·Ü∑/KoDALLE/loaded_VQGAN_blue.yaml\n",
            "1024 16 16\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Î≥ºÏù¥ ÎÑìÏùÄ Í≥ÑÎûÄÌòï ÏñºÍµ¥Ïù¥Î©∞ ÏïûÎ®∏Î¶¨Í∞Ä Ïù¥ÎßàÏùò ÏñëÏ™Ω ÎÅùÏùÑ Í∞ÄÎ¶¨Í≥† ÏûàÏñ¥ Î™®ÏñëÏùÄ Î≥¥Ïù¥ÏßÄ ÏïäÎäîÎã§.   Ïò§Î•∏Ï™Ω ÌÑ±Ïùò Í∞ÅÏßÑ Î∂ÄÎ∂ÑÏù¥ ÏôºÏ™ΩÏóê ÎπÑÌï¥ ÏïÑÎûòÎ°ú ÎÇ¥Î†§ÏôÄ ÏûàÍ≥† ÏôºÏ™ΩÏùÄ ÏïΩÍ∞Ñ ÏôÑÎßåÌïú ÌòïÌÉúÏù¥Îã§.  ÌÑ±ÎÅùÏúºÎ°ú ÎÇ¥Î†§Ïò§Îäî ÌÑ±Î™®ÏñëÏùÄ ÏïΩÍ∞Ñ Îë•Í∑ºÌòïÏúºÎ°ú Î≥¥Ïù∏Îã§. ÏôºÏ™ΩÏùò Î≥ºÏù¥ Îçî ÌèâÌèâÌïòÍ≥† ÎÑìÏùÄ Ìé∏Ïù¥Îã§.'\n",
        "\n",
        "encoded_dict = tokenizer(\n",
        "    text,\n",
        "    return_tensors=\"pt\",\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=DALLE_CFG.TEXT_SEQ_LEN,\n",
        "    add_special_tokens=True,\n",
        "    return_token_type_ids=True,  # for RoBERTa\n",
        ").to(device)\n",
        "\n",
        "encoded_text = encoded_dict['input_ids']\n",
        "mask = encoded_dict['attention_mask']\n",
        "\n",
        "print(encoded_text)\n",
        "print(mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9hljLgTfBqk",
        "outputId": "ed885b81-c291-480f-ffe1-910786aee268"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,  1164,  2052,   748,  2073,  8493,  2444,  3977,  2052,  2307,\n",
            "         24819,  2116,  8950,  2079,  8108,   711,  2069,  5246,  2088,  1513,\n",
            "          2051,  4616,  2073,  3783,  2118,  1380,  2259,  2062,    18,  6735,\n",
            "          1778,  2079,   544,  2043,  3884,  2052,  6561,  2170,  4357,  4402,\n",
            "          2200, 13567,  1513,  2088,  6561,  2073,  4943, 18026,  2470,  4337,\n",
            "         28674,    18,  1778,  3141,  6233,  9005,  2259,  1778,  2391,  2221,\n",
            "          2073,  4943, 15207,     2]], device='cuda:0')\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyhlZyIjoyOU",
        "outputId": "0e69dd66-9772-4b3a-fd25-a0fb0ed00503"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj4hKAtco0ZZ",
        "outputId": "fdc6e8ef-7e98-4e32-c59e-5bf738b4f57c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def exists(obj):\n",
        "    return obj is not None\n",
        "\n",
        "def is_empty(obj):\n",
        "  return not obj is not None\n",
        "\n",
        "def top_k(logits, thres):\n",
        "    # Assuming logits is a PyTorch tensor and you want the indices of the top k elements above a threshold\n",
        "    k = 5  # You can dynamically set k based on your requirements\n",
        "    # Return the values and indices where values are greater than a threshold\n",
        "    mask = logits > thres\n",
        "    values, indices = torch.topk(logits[mask], k=min(k, mask.sum()), largest=True, sorted=True)\n",
        "    return values\n",
        "\n",
        "my_vae = DiscreteVAE()\n",
        "my_depth = 12\n",
        "\n",
        "# DALLE_Klue_Roberta Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±\n",
        "dalle = DALLE_Klue_Roberta(vae=my_vae, depth=my_depth)\n",
        "\n",
        "image = dalle.generate_images(\n",
        "    encoded_dict,\n",
        "    #mask=mask,\n",
        "    filter_thres=0.9  # topk sampling at 0.9\n",
        ")\n",
        "\n",
        "image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "YbzXdXD8k7Hl",
        "outputId": "8fa38909-0b40-484a-8c5a-bf22e6aafafb"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'seek'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-c71ee20ec4c7>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# DALLE_Klue_Roberta Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdalle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDALLE_Klue_Roberta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_vae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m image = dalle.generate_images(\n",
            "\u001b[0;32m<ipython-input-77-2e342d942be4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vae, num_text_tokens, text_seq_len, depth, heads, dim_head, reversible, attn_dropout, ff_dropout, sparse_attn, attn_types, loss_img_weight, stable, sandwich_norm, shift_tokens, rotary_emb, wte_dir, wpe_dir)\u001b[0m\n\u001b[1;32m     55\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwte_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_image_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_open_buffer_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'r'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_open_buffer_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected 'r' or 'w' in mode but got {mode}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, buffer)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0m_check_seekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0mraise_err_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seek\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mraise_err_msg\u001b[0;34m(patterns, e)\u001b[0m\n\u001b[1;32m    534\u001b[0m                                 \u001b[0;34m+\u001b[0m \u001b[0;34m\" Please pre-load the data into a buffer like io.BytesIO and\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m                                 + \" try to load from it instead.\")\n\u001b[0;32m--> 536\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)\n",
        "\n",
        "T.ToPILImage()(image.squeeze())"
      ],
      "metadata": {
        "id": "G5KxfWseftxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_montage(text):\n",
        "    encoded_dict = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=DALLE_CFG.TEXT_SEQ_LEN,\n",
        "        add_special_tokens=True,\n",
        "        return_token_type_ids=True,  # for RoBERTa\n",
        "    ).to(device)\n",
        "\n",
        "    encoded_text = encoded_dict['input_ids']\n",
        "    mask = encoded_dict['attention_mask']\n",
        "\n",
        "    image = dalle.generate_images(\n",
        "        encoded_text,\n",
        "        mask=mask,\n",
        "        filter_thres=0.9  # topk sampling at 0.9\n",
        "    )\n",
        "\n",
        "    return T.ToPILImage()(image.squeeze())"
      ],
      "metadata": {
        "id": "W2SS5omQf0Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = input('text : ')\n",
        "text_to_montage(text)"
      ],
      "metadata": {
        "id": "rLUeEZ0Ff2LL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}